{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Model Development and Prediction Service\n",
    "\n",
    "## CS 4981 ML Production Systems\n",
    "\n",
    "## Kyle Robinson, Michael Salgado, Noah Stiemke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we are training different ham/spam classifier models using the labled emails stored in Minio. Throughout our training, we are testing different combinations of hyperparameters for both the models and the Count Vectorizer to find the model with the highest accuracy on our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    make_scorer,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathname = \"C:/Users/salgadom/Documents/CS4981/P1-repository/cs4981_lab1_email_classifier/part-00000-a994d54f-2d6b-4f3e-b9d1-21c14ae09d0a-c000.json\"\n",
    "\n",
    "email_data = []\n",
    "with open(pathname, encoding='utf8') as json_file:\n",
    "    for row in json_file:\n",
    "        row_data = json.loads(row)\n",
    "\n",
    "        row_dict = {'email_id': row_data['email_id'],\n",
    "                    'received_timestamp': row_data['received_timestamp'],\n",
    "                    'body': json.loads(row_data['email_object'])['body'],\n",
    "                    'label': row_data['label']}\n",
    "\n",
    "        email_data.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'email_id': 1, 'received_timestamp': '2023-05-04T09:59:48.492-05:00', 'body': '\\n\\n\\n\\n\\n\\n\\nDo you feel the pressure to perform and not rising to the occasion??\\n\\n\\n\\n\\nTry Viagra.....\\nyour anxiety will be a thing of the past and you will\\nbe back to your old self.\\n\\n', 'label': 'spam'}\n"
     ]
    }
   ],
   "source": [
    "print(email_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df = pd.DataFrame.from_dict(email_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>received_timestamp</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-04T09:59:48.492-05:00</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nDo you feel the pressure to perf...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-04T09:59:48.795-05:00</td>\n",
       "      <td>Hi, i've just updated from the gulus and I che...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2023-05-04T09:59:50.782-05:00</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n HoodiaLife - Start Losing Weight ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-05-04T09:59:48.956-05:00</td>\n",
       "      <td>authentic viagra\\n\\nMega  authenticV I A G R A...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-05-04T09:59:49.240-05:00</td>\n",
       "      <td>\\nHey Billy, \\n\\nit was really fun going out t...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   email_id             received_timestamp  \\\n",
       "0         1  2023-05-04T09:59:48.492-05:00   \n",
       "1         2  2023-05-04T09:59:48.795-05:00   \n",
       "2         8  2023-05-04T09:59:50.782-05:00   \n",
       "3         3  2023-05-04T09:59:48.956-05:00   \n",
       "4         4  2023-05-04T09:59:49.240-05:00   \n",
       "\n",
       "                                                body label  \n",
       "0  \\n\\n\\n\\n\\n\\n\\nDo you feel the pressure to perf...  spam  \n",
       "1  Hi, i've just updated from the gulus and I che...   ham  \n",
       "2  \\n\\n\\n\\n\\n\\n HoodiaLife - Start Losing Weight ...  spam  \n",
       "3  authentic viagra\\n\\nMega  authenticV I A G R A...  spam  \n",
       "4  \\nHey Billy, \\n\\nit was really fun going out t...  spam  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10801 entries, 0 to 10800\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   email_id            10801 non-null  int64 \n",
      " 1   received_timestamp  10801 non-null  object\n",
      " 2   body                10801 non-null  object\n",
      " 3   label               10801 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 337.7+ KB\n"
     ]
    }
   ],
   "source": [
    "emails_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataframe: 10801\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows in dataframe: {len(emails_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "- Convert to lowercase\n",
    "- Stop words?\n",
    "- Lemmitization\n",
    "- Balancing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of spam labels: 7604\n",
      "Original number of ham labels: 3197\n",
      "\n",
      "Adjusted number of spam labels: 3197\n",
      "Adjusted number of ham labels: 3197\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>received_timestamp</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-04T09:59:48.795-05:00</td>\n",
       "      <td>Hi, i've just updated from the gulus and I che...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1220</td>\n",
       "      <td>2023-05-04T10:04:36.681-05:00</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1292</td>\n",
       "      <td>2023-05-04T10:04:55.913-05:00</td>\n",
       "      <td>\\nGoogle News Alert for: bush\\n\\n\\nThe Bush ad...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>2023-05-04T09:59:51.142-05:00</td>\n",
       "      <td>\\nHi...\\n\\nI have to use R to find out the 90%...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17</td>\n",
       "      <td>2023-05-04T09:59:52.271-05:00</td>\n",
       "      <td>Hm... sounds like a homework problem to me...\\...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    email_id             received_timestamp  \\\n",
       "1          2  2023-05-04T09:59:48.795-05:00   \n",
       "11      1220  2023-05-04T10:04:36.681-05:00   \n",
       "13      1292  2023-05-04T10:04:55.913-05:00   \n",
       "14         9  2023-05-04T09:59:51.142-05:00   \n",
       "23        17  2023-05-04T09:59:52.271-05:00   \n",
       "\n",
       "                                                 body label  \n",
       "1   Hi, i've just updated from the gulus and I che...   ham  \n",
       "11  ----------------------------------------------...   ham  \n",
       "13  \\nGoogle News Alert for: bush\\n\\n\\nThe Bush ad...   ham  \n",
       "14  \\nHi...\\n\\nI have to use R to find out the 90%...   ham  \n",
       "23  Hm... sounds like a homework problem to me...\\...   ham  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails = emails_df[emails_df['label'] == 'spam']\n",
    "ham_emails = emails_df[emails_df['label'] == 'ham']\n",
    "\n",
    "num_spam = len(spam_emails)\n",
    "num_ham = len(ham_emails)\n",
    "\n",
    "print(f\"Original number of spam labels: {num_spam}\")\n",
    "print(f\"Original number of ham labels: {num_ham}\")\n",
    "\n",
    "undersample = None\n",
    "if num_spam > num_ham:\n",
    "    undersample = spam_emails.sample(n=len(ham_emails))\n",
    "    emails_df = pd.concat([ham_emails,undersample],axis=0)\n",
    "else:\n",
    "    undersample = ham_emails.sample(n=len(spam_emails))\n",
    "    emails_df = pd.concat([spam_emails,undersample],axis=0)\n",
    "\n",
    "print(f\"\\nAdjusted number of spam labels: {emails_df['label'].value_counts()['spam']}\")\n",
    "print(f\"Adjusted number of ham labels: {emails_df['label'].value_counts()['ham']}\")\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataframe: 6394\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows in dataframe: {len(emails_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting by time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting 'received_timestamp' to datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>received_timestamp</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-04T09:59:48.795-05:00</td>\n",
       "      <td>Hi, i've just updated from the gulus and I che...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1220</td>\n",
       "      <td>2023-05-04T10:04:36.681-05:00</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1292</td>\n",
       "      <td>2023-05-04T10:04:55.913-05:00</td>\n",
       "      <td>\\nGoogle News Alert for: bush\\n\\n\\nThe Bush ad...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>2023-05-04T09:59:51.142-05:00</td>\n",
       "      <td>\\nHi...\\n\\nI have to use R to find out the 90%...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17</td>\n",
       "      <td>2023-05-04T09:59:52.271-05:00</td>\n",
       "      <td>Hm... sounds like a homework problem to me...\\...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    email_id             received_timestamp  \\\n",
       "1          2  2023-05-04T09:59:48.795-05:00   \n",
       "11      1220  2023-05-04T10:04:36.681-05:00   \n",
       "13      1292  2023-05-04T10:04:55.913-05:00   \n",
       "14         9  2023-05-04T09:59:51.142-05:00   \n",
       "23        17  2023-05-04T09:59:52.271-05:00   \n",
       "\n",
       "                                                 body label  \n",
       "1   Hi, i've just updated from the gulus and I che...   ham  \n",
       "11  ----------------------------------------------...   ham  \n",
       "13  \\nGoogle News Alert for: bush\\n\\n\\nThe Bush ad...   ham  \n",
       "14  \\nHi...\\n\\nI have to use R to find out the 90%...   ham  \n",
       "23  Hm... sounds like a homework problem to me...\\...   ham  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>received_timestamp</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-04 09:59:48.795000-05:00</td>\n",
       "      <td>Hi, i've just updated from the gulus and I che...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1220</td>\n",
       "      <td>2023-05-04 10:04:36.681000-05:00</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1292</td>\n",
       "      <td>2023-05-04 10:04:55.913000-05:00</td>\n",
       "      <td>\\nGoogle News Alert for: bush\\n\\n\\nThe Bush ad...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>2023-05-04 09:59:51.142000-05:00</td>\n",
       "      <td>\\nHi...\\n\\nI have to use R to find out the 90%...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17</td>\n",
       "      <td>2023-05-04 09:59:52.271000-05:00</td>\n",
       "      <td>Hm... sounds like a homework problem to me...\\...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    email_id               received_timestamp  \\\n",
       "1          2 2023-05-04 09:59:48.795000-05:00   \n",
       "11      1220 2023-05-04 10:04:36.681000-05:00   \n",
       "13      1292 2023-05-04 10:04:55.913000-05:00   \n",
       "14         9 2023-05-04 09:59:51.142000-05:00   \n",
       "23        17 2023-05-04 09:59:52.271000-05:00   \n",
       "\n",
       "                                                 body label  \n",
       "1   Hi, i've just updated from the gulus and I che...   ham  \n",
       "11  ----------------------------------------------...   ham  \n",
       "13  \\nGoogle News Alert for: bush\\n\\n\\nThe Bush ad...   ham  \n",
       "14  \\nHi...\\n\\nI have to use R to find out the 90%...   ham  \n",
       "23  Hm... sounds like a homework problem to me...\\...   ham  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df['received_timestamp'] = pd.to_datetime(emails_df['received_timestamp'], format='%Y-%m-%dT%H:%M:%S')\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting dataframe by datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>received_timestamp</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-04 09:59:48.492000-05:00</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nDo you feel the pressure to perf...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-04 09:59:48.795000-05:00</td>\n",
       "      <td>Hi, i've just updated from the gulus and I che...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-05-04 09:59:48.956000-05:00</td>\n",
       "      <td>authentic viagra\\n\\nMega  authenticV I A G R A...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-05-04 09:59:49.511000-05:00</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nsystem\" of the home.  It will ha...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>2023-05-04 09:59:51.142000-05:00</td>\n",
       "      <td>\\nHi...\\n\\nI have to use R to find out the 90%...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10794</th>\n",
       "      <td>10792</td>\n",
       "      <td>2023-05-04 10:41:31.756000-05:00</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nModeling make specify fashion?...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10798</th>\n",
       "      <td>10795</td>\n",
       "      <td>2023-05-04 10:41:33.034000-05:00</td>\n",
       "      <td>Author: metze\\nDate: 2007-04-20 10:57:13 +0000...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>10796</td>\n",
       "      <td>2023-05-04 10:41:33.193000-05:00</td>\n",
       "      <td></td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10795</th>\n",
       "      <td>10798</td>\n",
       "      <td>2023-05-04 10:41:33.629000-05:00</td>\n",
       "      <td>Author: metze\\nDate: 2007-04-20 11:00:20 +0000...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800</th>\n",
       "      <td>10801</td>\n",
       "      <td>2023-05-04 10:41:34.320000-05:00</td>\n",
       "      <td>Author: metze\\nDate: 2007-04-20 11:02:45 +0000...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6394 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       email_id               received_timestamp  \\\n",
       "0             1 2023-05-04 09:59:48.492000-05:00   \n",
       "1             2 2023-05-04 09:59:48.795000-05:00   \n",
       "3             3 2023-05-04 09:59:48.956000-05:00   \n",
       "6             5 2023-05-04 09:59:49.511000-05:00   \n",
       "14            9 2023-05-04 09:59:51.142000-05:00   \n",
       "...         ...                              ...   \n",
       "10794     10792 2023-05-04 10:41:31.756000-05:00   \n",
       "10798     10795 2023-05-04 10:41:33.034000-05:00   \n",
       "10784     10796 2023-05-04 10:41:33.193000-05:00   \n",
       "10795     10798 2023-05-04 10:41:33.629000-05:00   \n",
       "10800     10801 2023-05-04 10:41:34.320000-05:00   \n",
       "\n",
       "                                                    body label  \n",
       "0      \\n\\n\\n\\n\\n\\n\\nDo you feel the pressure to perf...  spam  \n",
       "1      Hi, i've just updated from the gulus and I che...   ham  \n",
       "3      authentic viagra\\n\\nMega  authenticV I A G R A...  spam  \n",
       "6      \\n\\n\\n\\n\\n\\n\\nsystem\" of the home.  It will ha...  spam  \n",
       "14     \\nHi...\\n\\nI have to use R to find out the 90%...   ham  \n",
       "...                                                  ...   ...  \n",
       "10794  \\n\\n\\n\\n\\n\\n\\n\\nModeling make specify fashion?...  spam  \n",
       "10798  Author: metze\\nDate: 2007-04-20 10:57:13 +0000...   ham  \n",
       "10784                                                      ham  \n",
       "10795  Author: metze\\nDate: 2007-04-20 11:00:20 +0000...   ham  \n",
       "10800  Author: metze\\nDate: 2007-04-20 11:02:45 +0000...   ham  \n",
       "\n",
       "[6394 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.sort_values(by='received_timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The hyper-parameters that will be tested for this model are as follows:\n",
    "  - Regularization (0.01, 0.1, 1.0)\n",
    "  - Penalty Types (L1, L2)\n",
    "  - Solver (lbfgs, liblinear, newton-cg)\n",
    "  - min_df (0, 1, 10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting dataset by time\n",
    "Split by time, split first 80% for older timestamps, 20% for the latest timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(emails_df['body'].values, emails_df['label'], test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_parameters = {\n",
    "    'vectorizer__min_df': [10, 20],\n",
    "    'classifier__C': [0.01, 0.1, 1.0],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, LogisticRegression())]),\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 0.1, 1.0],\n",
       "                         &#x27;classifier__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;classifier__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                &#x27;liblinear&#x27;],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [10, 20]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;, LogisticRegression())]),\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 0.1, 1.0],\n",
       "                         &#x27;classifier__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;classifier__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                &#x27;liblinear&#x27;],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [10, 20]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid={'classifier__C': [0.01, 0.1, 1.0],\n",
       "                         'classifier__penalty': ['l1', 'l2'],\n",
       "                         'classifier__solver': ['newton-cg', 'lbfgs',\n",
       "                                                'liblinear'],\n",
       "                         'vectorizer__min_df': [10, 20]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lr_clf = GridSearchCV(lr_pipeline, lr_parameters, cv=10)\n",
    "lr_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg', 'vectorizer__min_df': 10}\n",
      "LogisticRegression(C=0.1, solver='newton-cg')\n",
      "CountVectorizer(min_df=10)\n"
     ]
    }
   ],
   "source": [
    "best_lr_output = lr_clf.best_estimator_\n",
    "\n",
    "best_lr_vectorizer = best_lr_output.named_steps['vectorizer']\n",
    "best_lr_model = best_lr_output.named_steps['classifier']\n",
    "best_params = lr_clf.best_params_\n",
    "print(best_params)\n",
    "print(best_lr_model)\n",
    "print(best_lr_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating best model on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics: {'accuracy': 0.9890539483971853, 'precision': 1.0, 'recall': 0.9890539483971853, 'f1': 0.9944968553459119}\n"
     ]
    }
   ],
   "source": [
    "x_test_counts = best_lr_vectorizer.transform(x_test)\n",
    "y_test_pred = best_lr_model.predict(x_test_counts)\n",
    "\n",
    "# Evaluate the performance on the testing set\n",
    "lr_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "lr_precision = precision_score(y_test, y_test_pred, pos_label=\"spam\")\n",
    "lr_recall = recall_score(y_test, y_test_pred, pos_label=\"spam\")\n",
    "lr_f1 = f1_score(y_test, y_test_pred, pos_label=\"spam\")\n",
    "\n",
    "# Output the evaluation metrics\n",
    "lr_evaluation_metrics = {\n",
    "    'accuracy': lr_accuracy,\n",
    "    'precision': lr_precision,\n",
    "    'recall': lr_recall,\n",
    "    'f1': lr_f1\n",
    "}\n",
    "\n",
    "print(\"Testing Metrics:\", lr_evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into training and testing sets by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(emails_df['body'].values, emails_df['label'], test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining parameters for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_parameters = {\n",
    "    'vectorizer__min_df': [0, 1, 10, 20],\n",
    "    \"classifier__n_estimators\": [10, 50, 100],\n",
    "    \"classifier__max_depth\": [5, 10, 20],\n",
    "    \"classifier__min_samples_leaf\": [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing random forest classifier and performing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={&#x27;classifier__max_depth&#x27;: [5, 10, 20],\n",
       "                         &#x27;classifier__min_samples_leaf&#x27;: [1, 3, 5],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [10, 50, 100],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 1, 10, 20]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={&#x27;classifier__max_depth&#x27;: [5, 10, 20],\n",
       "                         &#x27;classifier__min_samples_leaf&#x27;: [1, 3, 5],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [10, 50, 100],\n",
       "                         &#x27;vectorizer__min_df&#x27;: [0, 1, 10, 20]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={'classifier__max_depth': [5, 10, 20],\n",
       "                         'classifier__min_samples_leaf': [1, 3, 5],\n",
       "                         'classifier__n_estimators': [10, 50, 100],\n",
       "                         'vectorizer__min_df': [0, 1, 10, 20]})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rfc_clf = GridSearchCV(rfc_pipeline, rfc_parameters, cv=10)\n",
    "rfc_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__n_estimators': 50, 'vectorizer__min_df': 20}\n",
      "RandomForestClassifier(max_depth=20, n_estimators=50)\n",
      "CountVectorizer(min_df=20)\n"
     ]
    }
   ],
   "source": [
    "best_rfc_output = rfc_clf.best_estimator_\n",
    "best_rfc_vectorizer = best_rfc_output.named_steps['vectorizer']\n",
    "best_rfc_model = best_rfc_output.named_steps['classifier']\n",
    "best_rfc_params = rfc_clf.best_params_\n",
    "print(best_rfc_params)\n",
    "print(best_rfc_model)\n",
    "print(best_rfc_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating best model on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics: {'accuracy': 0.9788897576231431, 'precision': 1.0, 'recall': 0.9788897576231431, 'f1': 0.9893322797313315}\n"
     ]
    }
   ],
   "source": [
    "# Predict labels for the testing data using the trained random forest model\n",
    "x_test_counts = best_rfc_vectorizer.transform(x_test)\n",
    "y_test_pred = best_rfc_model.predict(x_test_counts)\n",
    "\n",
    "# Evaluate the performance on the testing set\n",
    "rf_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "rf_precision = precision_score(y_test, y_test_pred, pos_label=\"spam\")\n",
    "rf_recall = recall_score(y_test, y_test_pred, pos_label=\"spam\")\n",
    "rf_f1 = f1_score(y_test, y_test_pred, pos_label=\"spam\")\n",
    "\n",
    "# Output the evaluation metrics\n",
    "rf_evaluation_metrics = {\n",
    "    'accuracy': rf_accuracy,\n",
    "    'precision': rf_precision,\n",
    "    'recall': rf_recall,\n",
    "    'f1': rf_f1\n",
    "}\n",
    "\n",
    "print(\"Testing Metrics:\", rf_evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Evaluation\n",
    "\n",
    "The models with the best metrics for each approach are as follows: \n",
    " - **Logistic Regression**: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg', 'vectorizer__min_df': 10}\n",
    "   - Testing Metrics: {'accuracy': 0.9890539483971853, 'precision': 1.0, 'recall': 0.9890539483971853, 'f1': 0.9944968553459119}\n",
    " - **Random Forest**: {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__n_estimators': 50, 'vectorizer__min_df': 20}\n",
    "    - Testing Metrics: {'accuracy': 0.9788897576231431, 'precision': 1.0, 'recall': 0.9788897576231431, 'f1': 0.9893322797313315}\n",
    "    \n",
    "According to these results, the Logistic Regression model performed the best with an accuracy of 0.986 and an f1-score of 0.993"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(emails_df['body'].values, emails_df['label'], test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting data using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_counts = best_lr_vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training LR model using best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, solver='newton-cg')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_model.fit(x_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics: {'best_params': {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg', 'vectorizer__min_df': 10}, 'metrics': {'accuracy': 0.9890539483971853, 'precision': 1.0, 'recall': 0.9890539483971853, 'f1': 0.9944968553459119}}\n"
     ]
    }
   ],
   "source": [
    "x_test_counts = best_lr_vectorizer.transform(x_test)\n",
    "y_test_pred = best_lr_model.predict(x_test_counts)\n",
    "\n",
    "# Evaluate the performance on the testing set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, pos_label=\"spam\")\n",
    "recall = recall_score(y_test, y_test_pred, pos_label=\"spam\")\n",
    "f1 = f1_score(y_test, y_test_pred, pos_label=\"spam\")\n",
    "\n",
    "# Store the parameters and metrics in a dictionary\n",
    "results = {\n",
    "    'best_params': best_params,\n",
    "    'metrics': {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Testing Metrics:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving results as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results as a JSON file\n",
    "output_filename = datetime.now().strftime(\"model_results_%Y-%m-%d_%H-%M-%S.json\")\n",
    "with open(output_filename, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
